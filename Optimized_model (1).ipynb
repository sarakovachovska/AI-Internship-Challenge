{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pi438gaKdIq",
        "outputId": "a9a68961-4f40-4c06-dd7b-469f065bdb71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.11/dist-packages (0.9.3)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.13.6)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.1.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu fasttext flask fuzzywuzzy requests numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import fasttext\n",
        "import faiss\n",
        "import json\n",
        "import re\n",
        "import requests\n",
        "import os\n",
        "from flask import Flask, request, jsonify\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Paths for saving models\n",
        "faiss_dir = \"/content/drive/MyDrive/Faiss_Index\"\n",
        "faiss_index_path = os.path.join(faiss_dir, \"faiss.index\")\n",
        "embeddings_path = os.path.join(faiss_dir, \"admin_embeddings.npy\")\n",
        "conceptnet_cache_path = os.path.join(faiss_dir, \"conceptnet_cache.json\")\n",
        "\n",
        "# Ensure directory exists\n",
        "if not os.path.exists(faiss_dir):\n",
        "    os.makedirs(faiss_dir)\n",
        "    print(\"Created directory:\", faiss_dir)\n",
        "\n",
        "# Load FastText model\n",
        "model_path = \"/content/drive/MyDrive/FastText_Models/cc.en.300.bin\"\n",
        "fasttext_model = fasttext.load_model(model_path)\n",
        "\n",
        "# **Admin-defined skill list (normalized)**\n",
        "admin_skill_list = [\"python\", \"relational database\", \"software engineering\", \"data science\", \"nlp\", \"natural language processing\"]\n",
        "\n",
        "# **Load FAISS embeddings**\n",
        "if os.path.exists(embeddings_path):\n",
        "    print(\"Loading embeddings from Drive...\")\n",
        "    admin_embeddings = np.load(embeddings_path)\n",
        "else:\n",
        "    print(\"Embeddings not found, creating new ones...\")\n",
        "    admin_embeddings = np.array([fasttext_model.get_word_vector(skill) for skill in admin_skill_list])\n",
        "    np.save(embeddings_path, admin_embeddings)  # Save for future use\n",
        "\n",
        "# **Load FAISS index**\n",
        "if os.path.exists(faiss_index_path):\n",
        "    print(\"Loading FAISS index from Drive...\")\n",
        "    faiss_index = faiss.read_index(faiss_index_path)\n",
        "else:\n",
        "    print(\"FAISS index not found, creating new one...\")\n",
        "    faiss_index = faiss.IndexHNSWFlat(300, 32)\n",
        "    faiss_index.add(admin_embeddings)\n",
        "    faiss.write_index(faiss_index, faiss_index_path)\n",
        "\n",
        "# **MiniDBpedia (Keys = Skills from Admin List)**\n",
        "miniDBpedia = {\n",
        "    \"python\": [\"scripting\", \"software development\"],\n",
        "    \"relational database\": [\"sql\", \"postgresql\", \"mysql\"],\n",
        "    \"software engineering\": [\"agile development\", \"devops\", \"software development\"],\n",
        "    \"data science\": [\"data analysis\", \"big data\", \"machine learning\"],\n",
        "    \"nlp\": [\"natural language processing\", \"text analysis\", \"ner\", \"transformers\", \"text mining\", \"linguistics\"],\n",
        "    \"natural language processing\": [\"nlp\", \"text mining\", \"text analysis\", \"ner\", \"transformers\", \"linguistics\"]\n",
        "}\n",
        "\n",
        "# **Abbreviations Dictionary**\n",
        "abbreviations = {\n",
        "    \"py\": \"python\",\n",
        "    \"db\": \"relational database\",\n",
        "    \"se\": \"software engineering\",\n",
        "    \"ds\": \"data science\",\n",
        "    \"nlp\": \"natural language processing\"\n",
        "}\n",
        "\n",
        "# **Normalize Function**\n",
        "def normalize_text(skill):\n",
        "    skill = skill.lower().strip()\n",
        "    skill = re.sub(r'[^a-zA-Z0-9\\s]', '', skill)\n",
        "    return skill\n",
        "\n",
        "# **Sequence Matcher for Similarity Check**\n",
        "def similar_match(skill, skill_list, threshold=0.8):\n",
        "    for s in skill_list:\n",
        "        if SequenceMatcher(None, skill, s).ratio() > threshold:\n",
        "            return s\n",
        "    return None\n",
        "\n",
        "# **Function to Generate Word Embeddings**\n",
        "def get_mean_embedding(skill):\n",
        "    words = skill.split()\n",
        "    word_vectors = [fasttext_model.get_word_vector(w) for w in words]\n",
        "    return np.mean(word_vectors, axis=0) if word_vectors else np.zeros(300)\n",
        "\n",
        "# **ConceptNet API Query**\n",
        "def query_conceptnet(skill):\n",
        "    api_url = f\"http://api.conceptnet.io/c/en/{skill}\"\n",
        "    try:\n",
        "        response = requests.get(api_url).json()\n",
        "        related_skills = []\n",
        "        for edge in response.get(\"edges\", []):\n",
        "            relation = edge.get(\"rel\", {}).get(\"label\", \"\").lower()\n",
        "            target = edge.get(\"end\", {}).get(\"label\", \"\").lower()\n",
        "            if relation in [\"synonym\", \"relatedto\", \"isa\", \"partof\"] and target in admin_skill_list:\n",
        "                related_skills.append({\"matched_skill\": target, \"matching_method\": relation})\n",
        "        return related_skills\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "# **Semantic Similarity Matching with FAISS**\n",
        "def match_with_admin_skills(user_skill):\n",
        "    user_vec = get_mean_embedding(user_skill).reshape(1, -1)\n",
        "    distances, indices = faiss_index.search(user_vec, k=1)  # Get best match\n",
        "\n",
        "    threshold = 0.8\n",
        "    min_similarity = 0.7\n",
        "\n",
        "    matches = []\n",
        "    for idx, dist in zip(indices[0], distances[0]):\n",
        "        similarity_score = 1 / (1 + dist)\n",
        "        if dist < threshold and similarity_score >= min_similarity:\n",
        "            matches.append({\"matched_skill\": admin_skill_list[idx], \"matching_method\": \"semantic_similarity\"})\n",
        "\n",
        "    return matches\n",
        "\n",
        "# **Flask API**\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/match_skill', methods=['POST'])\n",
        "def match_skills():\n",
        "    data = request.get_json()\n",
        "    user_queries = data.get(\"skills\", [])\n",
        "    if not isinstance(user_queries, list) or not user_queries:\n",
        "        return jsonify({\"error\": \"No skills provided or incorrect format\"}), 400\n",
        "\n",
        "    final_results = []\n",
        "    for user_query in user_queries:\n",
        "        normalized_skill = normalize_text(user_query)\n",
        "        match_results = []\n",
        "\n",
        "        # **1. Exact Match or Abbreviation**\n",
        "        if normalized_skill in admin_skill_list:\n",
        "            match_results.append({\"matched_skill\": normalized_skill, \"matching_method\": \"exact_match\"})\n",
        "        elif normalized_skill in abbreviations:\n",
        "            match_results.append({\"matched_skill\": abbreviations[normalized_skill], \"matching_method\": \"abbreviation\"})\n",
        "\n",
        "        # **2. Misspelling Correction**\n",
        "        elif similar_match(normalized_skill, admin_skill_list):\n",
        "            match_results.append({\"matched_skill\": similar_match(normalized_skill, admin_skill_list), \"matching_method\": \"misspelling\"})\n",
        "\n",
        "        # **3. MiniDBpedia Mapping**\n",
        "        else:\n",
        "            for key, values in miniDBpedia.items():\n",
        "                if normalized_skill in values:\n",
        "                    match_results.append({\"matched_skill\": key, \"matching_method\": \"knowledge_graph\"})\n",
        "                    break\n",
        "\n",
        "        # **4. Semantic Similarity Matching (FastText + FAISS)**\n",
        "        if not match_results:\n",
        "            match_results.extend(match_with_admin_skills(normalized_skill))\n",
        "\n",
        "        # **5. ConceptNet Knowledge Graph Lookup**\n",
        "        if not match_results:\n",
        "            match_results.extend(query_conceptnet(normalized_skill))\n",
        "\n",
        "        # **Only Append if Matches Exist**\n",
        "        if match_results:\n",
        "            final_results.append({\"user_skill\": user_query, \"matches\": match_results})\n",
        "\n",
        "    return jsonify({\"query_results\": final_results}), 200\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJx3df5LKevw",
        "outputId": "1c191e57-6a12-4c75-a676-a267152b630a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Loading embeddings from Drive...\n",
            "Loading FAISS index from Drive...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from threading import Thread\n",
        "\n",
        "def run_flask():\n",
        "    app.run(host=\"0.0.0.0\", port=5000)\n",
        "\n",
        "flask_thread = Thread(target=run_flask)\n",
        "flask_thread.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hcsMrnuK3t_",
        "outputId": "47ade1bb-7bb5-4e7e-a744-b0993e9111c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"http://127.0.0.1:5000/match_skill\"\n",
        "data = {\"skills\": [\"data science\", \"machine learning\", \"mysql\",\"random skill\"]}\n",
        "\n",
        "response = requests.post(url, json=data)\n",
        "print(response.json())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTJcCDBaLYLA",
        "outputId": "d2143e6d-a15a-43ce-e76b-0ca968187702"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [14/Feb/2025 02:01:50] \"POST /match_skill HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query_results': [{'matches': [{'matched_skill': 'data science', 'matching_method': 'exact_match'}], 'user_skill': 'data science'}, {'matches': [{'matched_skill': 'data science', 'matching_method': 'knowledge_graph'}], 'user_skill': 'machine learning'}, {'matches': [{'matched_skill': 'relational database', 'matching_method': 'knowledge_graph'}], 'user_skill': 'mysql'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NAKk1kYuLa0h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}